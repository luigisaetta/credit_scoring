{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b874f75a",
   "metadata": {},
   "source": [
    "### Prepare Deploy\n",
    "* save the model to the model catalog and prepare deployment as **REST service**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06e4f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "from ads.common.model_export_util import prepare_generic_model\n",
    "from ads.common.model_metadata import (MetadataCustomCategory,\n",
    "                                       UseCaseType)\n",
    "from ads import set_auth\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143b4f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # env and auth\n",
    "compartment_id = os.environ['NB_SESSION_COMPARTMENT_OCID']\n",
    "project_id = os.environ['PROJECT_OCID']\n",
    "\n",
    "set_auth(auth='resource_principal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a459e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. prepare artifacts directory\n",
    "\n",
    "PATH_ARTEFACT = f\"./model-files\"\n",
    "\n",
    "if not os.path.exists(PATH_ARTEFACT):\n",
    "    os.mkdir(PATH_ARTEFACT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f83356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE_NAME = \"credit-scoring.pkl\"\n",
    "SCALER_FILE_NAME = \"scaler.pkl\"\n",
    "\n",
    "model = pickle.load(open(PATH_ARTEFACT + \"/\" + MODEL_FILE_NAME, 'rb'))\n",
    "scaler = pickle.load(open(PATH_ARTEFACT + \"/\" + SCALER_FILE_NAME, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "144b928d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ADS:As force_overwrite is set to True, all the existing files in the ./model-files will be removed\n"
     ]
    }
   ],
   "source": [
    "# 2. prepare deploy to Model Catalog\n",
    "# this URL is taken from the Conda published env\n",
    "INFERENCE_ENV = \"oci://conda_ds@frqap2zhtzbe/conda_environments/cpu/General Machine Learning for CPUs on Python 3.7/1.0/generalml_p37_cpu_v1\"\n",
    "\n",
    "artifact = prepare_generic_model(model=model, model_path=PATH_ARTEFACT,\n",
    "                                 inference_conda_env=INFERENCE_ENV,\n",
    "                                 force_overwrite=True, data_science_env=False,\n",
    "                                 use_case_type=UseCaseType.BINARY_CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d79aad",
   "metadata": {},
   "source": [
    "### Customize score.py\n",
    "\n",
    "any customization you want to add to the main code f the REST service should be generated in this cell below\n",
    "\n",
    "before executing artifact.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d59a4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./model-files/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {PATH_ARTEFACT}/score.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import io\n",
    "import logging \n",
    "\n",
    "# logging configuration - OPTIONAL \n",
    "logging.basicConfig(format='%(name)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger_pred = logging.getLogger('model-prediction')\n",
    "logger_pred.setLevel(logging.INFO)\n",
    "logger_feat = logging.getLogger('input-features')\n",
    "logger_feat.setLevel(logging.INFO)\n",
    "\n",
    "model_name = 'credit-scoring.pkl'\n",
    "scaler_name = 'scaler.pkl'\n",
    "\n",
    "# scaler is global\n",
    "scaler = None\n",
    "\n",
    "# to enable/disable detailed logging\n",
    "DEBUG = True\n",
    "\n",
    "\"\"\"\n",
    "   Inference script. This script is used for prediction by scoring server when schema is known.\n",
    "\"\"\"\n",
    "\n",
    "def load_model(model_file_name=model_name):\n",
    "    \"\"\"\n",
    "    Loads model from the serialized format\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model:  a model instance on which predict API can be invoked\n",
    "    \"\"\"\n",
    "    global scaler\n",
    "    \n",
    "    model_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "    contents = os.listdir(model_dir)\n",
    "    \n",
    "    # Load the model from the model_dir using the appropriate loader\n",
    "    \n",
    "    if model_file_name in contents:\n",
    "        with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), model_file_name), \"rb\") as file:\n",
    "            model = pickle.load(file) \n",
    "            logger_pred.info(\"Loaded the model !!!\")\n",
    "            \n",
    "            with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), scaler_name), \"rb\") as file_sc:\n",
    "                scaler = pickle.load(file_sc)\n",
    "                logger_pred.info(\"Loaded the scaler !!!\")\n",
    "                \n",
    "    else:\n",
    "        raise Exception('{0} is not found in model directory {1}'.format(model_file_name, model_dir))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def pre_inference(data):\n",
    "    \"\"\"\n",
    "    Preprocess data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Data format as expected by the predict API of the core estimator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: Data format after any processing.\n",
    "\n",
    "    \"\"\"\n",
    "    logger_pred.info(\"Preprocessing...\")\n",
    "    \n",
    "    # first scaling\n",
    "    data_scaled = scaler.transform(data)\n",
    "    \n",
    "    # we assume no null, so we need only to add two columns with zero\n",
    "    # this is the matrix with right rows and two cols\n",
    "    z = np.zeros((data_scaled.shape[0],2))\n",
    "    \n",
    "    data = np.concatenate((data_scaled, z), axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def post_inference(yhat):\n",
    "    \"\"\"\n",
    "    Post-process the model results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yhat: Data format after calling model.predict.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    yhat: Data format after any processing.\n",
    "\n",
    "    \"\"\"\n",
    "    logger_pred.info(\"Postprocessing output...\")\n",
    "    \n",
    "    return yhat\n",
    "\n",
    "def predict(data, model=load_model()):\n",
    "    \"\"\"\n",
    "    Returns prediction given the model and data to predict\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Model instance returned by load_model API\n",
    "    data: Data format as expected by the predict API of the core estimator. For eg. in case of sckit models it could be numpy array/List of list/Pandas DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions: Output from scoring server\n",
    "        Format: {'prediction': output from model.predict method}\n",
    "\n",
    "    \"\"\"\n",
    "    global scaler\n",
    "    \n",
    "    # model contains the model and the scaler\n",
    "    logger_pred.info(\"In function predict...\")\n",
    "    \n",
    "    # some check\n",
    "    assert model is not None, \"Model is not loaded\"\n",
    "    assert scaler is not None, \"Scaler is not loaded\"\n",
    "    \n",
    "    x = pd.read_json(io.StringIO(data)).values\n",
    "    \n",
    "    if DEBUG:\n",
    "        logger_feat.info(\"Logging features\")\n",
    "        logger_feat.info(x)\n",
    "    \n",
    "    # preprocess data (for example normalize features)\n",
    "    x = pre_inference(x)\n",
    "\n",
    "    logger_pred.info(\"Invoking model......\")\n",
    "    \n",
    "    # compute predictions (binary, from model)\n",
    "    preds = model.predict(x)\n",
    "    \n",
    "    # to avoid not JSON serialiable erro (np.array is not)\n",
    "    preds = preds.tolist()\n",
    "    \n",
    "    # post inference not needed\n",
    "    return {'prediction': preds}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ec7659",
   "metadata": {},
   "source": [
    "### Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87b10130",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "# %load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "# add the path of score.py: \n",
    "\n",
    "import sys \n",
    "sys.path.insert(0, PATH_ARTEFACT)\n",
    "\n",
    "from score import load_model, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "993296aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:model-prediction:Loaded the model !!!\n",
      "INFO:model-prediction:Loaded the scaler !!!\n"
     ]
    }
   ],
   "source": [
    "# Load the model to memory \n",
    "_ = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc20770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:model-prediction:In function predict...\n",
      "INFO:input-features:Logging features\n",
      "INFO:input-features:[[ 1  2  3  4  5  6  7  8  9 10]\n",
      " [ 1  2  3  4  5  6  7  8  9 10]\n",
      " [ 1  2  3  4  5  6  7  8  9 10]\n",
      " [ 1  2  3  4  5  6  7  8  9 10]]\n",
      "INFO:model-prediction:Preprocessing...\n",
      "INFO:model-prediction:Invoking model......\n",
      "Tests results:\n",
      "{'prediction': [1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "x_input = np.array([[1,2,3,4,5,6,7,8,9,10],\n",
    "                   [1,2,3,4,5,6,7,8,9,10],\n",
    "                   [1,2,3,4,5,6,7,8,9,10],\n",
    "                   [1,2,3,4,5,6,7,8,9,10]])\n",
    "\n",
    "predictions_test = predict(json.dumps(x_input.tolist()), _)\n",
    "\n",
    "print(\"Tests results:\")\n",
    "print(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82521510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:model-prediction:In function predict...\n",
      "INFO:input-features:Logging features\n",
      "INFO:input-features:[[4.54238640e-02 6.40000000e+01 0.00000000e+00 1.81311286e-01\n",
      "  5.20000000e+03 4.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.11954668e-01 6.10000000e+01 0.00000000e+00 2.69281443e-01\n",
      "  9.86600000e+03 1.20000000e+01 0.00000000e+00 2.00000000e+00\n",
      "  0.00000000e+00 2.00000000e+00]\n",
      " [7.87389160e-02 4.60000000e+01 0.00000000e+00 1.66215372e-01\n",
      "  4.80000000e+03 6.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 4.00000000e+00]\n",
      " [1.37609462e-01 4.90000000e+01 0.00000000e+00 4.29533892e-01\n",
      "  7.27200000e+03 1.10000000e+01 0.00000000e+00 2.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.01730380e-02 6.40000000e+01 0.00000000e+00 1.73869570e-01\n",
      "  9.00000000e+03 8.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.19783750e-02 4.00000000e+01 0.00000000e+00 4.43755624e-01\n",
      "  1.00000000e+04 1.20000000e+01 0.00000000e+00 5.00000000e+00\n",
      "  0.00000000e+00 2.00000000e+00]\n",
      " [4.43696851e-01 2.70000000e+01 0.00000000e+00 2.43400750e-02\n",
      "  5.83300000e+03 4.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.50679300e-03 6.00000000e+01 0.00000000e+00 1.25300000e+03\n",
      "  5.40000000e+03 8.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [4.66403280e-02 9.20000000e+01 1.00000000e+00 3.43266690e-02\n",
      "  2.65000000e+03 1.30000000e+01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.92365949e-01 5.00000000e+01 0.00000000e+00 4.20180551e-01\n",
      "  8.75000000e+03 8.00000000e+00 0.00000000e+00 2.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.08082760e-01 6.40000000e+01 0.00000000e+00 2.82600000e+03\n",
      "  5.40000000e+03 1.40000000e+01 0.00000000e+00 2.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99999900e-01 6.60000000e+01 1.00000000e+00 3.58101135e-01\n",
      "  1.93700000e+03 4.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.35008240e-02 5.30000000e+01 0.00000000e+00 1.83464028e-01\n",
      "  1.90000000e+04 8.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 2.00000000e+00]\n",
      " [9.99999900e-01 6.20000000e+01 0.00000000e+00 4.96583900e-02\n",
      "  6.00000000e+03 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.55316473e-01 6.30000000e+01 0.00000000e+00 5.22300000e+03\n",
      "  5.40000000e+03 1.90000000e+01 0.00000000e+00 2.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99999900e-01 5.00000000e+01 2.00000000e+00 1.20800000e+03\n",
      "  5.40000000e+03 4.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.81139570e-02 6.10000000e+01 0.00000000e+00 3.13493870e-02\n",
      "  2.20000000e+03 1.20000000e+01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.22696207e-01 4.20000000e+01 0.00000000e+00 8.00000000e+02\n",
      "  1.00000000e+00 3.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 2.00000000e+00]\n",
      " [5.93985244e-01 6.30000000e+01 0.00000000e+00 3.32698534e-01\n",
      "  5.25000000e+03 4.00000000e+00 0.00000000e+00 2.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.75081780e-02 7.30000000e+01 1.00000000e+00 1.35589153e-01\n",
      "  4.16600000e+03 1.20000000e+01 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "INFO:model-prediction:Preprocessing...\n",
      "INFO:model-prediction:Invoking model......\n",
      "Tests results:\n",
      "{'prediction': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n",
      "Expected labels:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# now test with real values taken from train set\n",
    "file_test = './cs-training.csv'\n",
    "\n",
    "START = 200\n",
    "END = 220\n",
    "\n",
    "TARGET = 'SeriousDlqin2yrs'\n",
    "features = ['RevolvingUtilizationOfUnsecuredLines', 'age',\n",
    "            'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome',\n",
    "            'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n",
    "            'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n",
    "            'NumberOfDependents']\n",
    "\n",
    "# last parameter to avoid too many decimal digits\n",
    "# it's a problems with float in Pandas\n",
    "dati_orig = pd.read_csv(file_test, float_precision='round_trip')\n",
    "\n",
    "dati_test = dati_orig[features]\n",
    "labels = dati_orig[TARGET].values\n",
    "\n",
    "# fix null values\n",
    "condition = dati_test.isna()['NumberOfDependents']\n",
    "dati_test.loc[condition, 'NumberOfDependents'] = 0\n",
    "\n",
    "condition = dati_test.isna()['MonthlyIncome']\n",
    "dati_test.loc[condition, 'MonthlyIncome'] = 5400\n",
    "\n",
    "x_input = dati_test[START:END].values\n",
    "\n",
    "predictions_test = predict(json.dumps(x_input.tolist()), _)\n",
    "\n",
    "print(\"Tests results:\")\n",
    "print(predictions_test)\n",
    "print()\n",
    "print(\"Expected labels:\")\n",
    "print(labels[START:END])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f961d0c",
   "metadata": {},
   "source": [
    "### Save the model to the Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca408def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact:/tmp/saved_model_fe016e20-4481-4562-8844-b64465619810.zip\n"
     ]
    }
   ],
   "source": [
    "# Saving the model artifact to the model catalog.\n",
    "catalog_entry = artifact.save(display_name='credit-scoring', \n",
    "              description='A model for credit scoring')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f06079",
   "metadata": {},
   "source": [
    "### At this point you have to deploy from the Console UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a16cb",
   "metadata": {},
   "source": [
    "### Test the deployed model\n",
    "\n",
    "After the successful creation of the Model Deployment you can test the endpoint with the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6012952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import oci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe94165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = \"https://modeldeployment.eu-frankfurt-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.eu-frankfurt-1.amaaaaaangencdyaozcafif4lrslx2thb4evzqnjk37uhptqodoa3z5inhaa/predict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbbd41cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the results from the deployed model:\n",
      "{'prediction': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# again using RP\n",
    "rps = oci.auth.signers.get_resource_principals_signer()\n",
    "\n",
    "# payload goes here\n",
    "body = json.dumps(x_input.tolist()) \n",
    "\n",
    "print(\"These are the results from the deployed model:\")\n",
    "print(requests.post(ENDPOINT, json=body, auth=rps).json())\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0808a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_cpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_cpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
