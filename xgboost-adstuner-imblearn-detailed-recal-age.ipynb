{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with ADSTuner for HPO\n",
    "\n",
    "* Imblearn for undersampling of negative class\n",
    "* ADSTuner for HPO\n",
    "* tuning on more parameters\n",
    "* optimize using recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "import ads\n",
    "\n",
    "# to use ADSTuner\n",
    "from ads.hpo.search_cv import ADSTuner\n",
    "from ads.hpo.stopping_criterion import *\n",
    "from ads.hpo.distributions import *\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# for undersampling the negative class\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.4\n"
     ]
    }
   ],
   "source": [
    "# check the ADS version\n",
    "print(ads.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants\n",
    "SEED = 1324\n",
    "\n",
    "# number of features (without (16/03) the two indicator cols)\n",
    "N_FEATURES = 12 - 2\n",
    "\n",
    "# name of col with label\n",
    "TARGET = 'SeriousDlqin2yrs'\n",
    "\n",
    "# cols with missing values\n",
    "COL1_MISSING = 'MonthlyIncome'\n",
    "COL2_MISSING = 'NumberOfDependents'\n",
    "\n",
    "# nomi delle due colonne indicator (valgono 1 laddove il dato Ã¨ inputato)\n",
    "IND1 = 'isna_mi'\n",
    "IND2 = 'isna_nod'\n",
    "\n",
    "ind_col = [IND1, IND2]\n",
    "\n",
    "# 16/03 added indicators\n",
    "COLS_TO_DROP = ['id', 'isna_mi', 'isna_nod']\n",
    "\n",
    "# for undersampling to make the dataset more balanced\n",
    "# ratio minority samples/majority\n",
    "# with this ratio I get all the positive samples\n",
    "RATIO = 1./5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset, not undersampled\n",
    "data_full = pd.read_csv('cs-training-nonull.csv')\n",
    "\n",
    "# remove unneeded cols\n",
    "data_full = data_full.drop(COLS_TO_DROP, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['age','NumberOfTime30-59DaysPastDueNotWorse',\n",
    "               'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n",
    "               'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n",
    "               'NumberOfDependents']\n",
    "num_cols = ['RevolvingUtilizationOfUnsecuredLines', 'DebtRatio', 'MonthlyIncome', ]\n",
    "\n",
    "# indicators are not touched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling and label encoding is done on data_full. After we will do resampling\n",
    "# In this way coding and scaling cover entire range of values, not only for resampled data\n",
    "\n",
    "# we don't need any scaling (it is ensambles of trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat cols treatment\n",
    "# Code categorical columns (only season, weather, year)\n",
    "\n",
    "# we don't need any pre-processing for cat columns\n",
    "\n",
    "# so for XGBoost  Nan treatment no other pre-processing is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with anomalous age\n",
    "# condition to keep\n",
    "condition = (data_full['age'] >= 18) & (data_full['age'] <= 100)\n",
    "\n",
    "data_full = data_full.loc[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract X: features and y, labels\n",
    "features = [c for c in data_full.columns if c != TARGET]\n",
    "\n",
    "y_train_full = data_full[TARGET].values\n",
    "x_train_full = data_full.drop(TARGET, axis = 1).values\n",
    "\n",
    "assert x_train_full.shape[1] == N_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples in full dataset: 149986\n",
      "# of positive samples: 10025\n",
      "# of negative samples: 139961\n"
     ]
    }
   ],
   "source": [
    "print(f'# of samples in full dataset: {x_train_full.shape[0]}')\n",
    "print(f'# of positive samples: {np.sum(y_train_full)}')\n",
    "print(f'# of negative samples: {x_train_full.shape[0] - np.sum(y_train_full)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples in resampled dataset: 60150\n",
      "# of positive samples: 10025\n",
      "# of negative samples: 50125\n"
     ]
    }
   ],
   "source": [
    "# do the undersampling of the negative class, using IMblearn\n",
    "rus = RandomUnderSampler(sampling_strategy=RATIO, random_state=SEED)\n",
    "\n",
    "x_train, y_train = rus.fit_resample(x_train_full, y_train_full)\n",
    "\n",
    "print(f'# of samples in resampled dataset: {x_train.shape[0]}')\n",
    "\n",
    "# check ratio of classes\n",
    "print(f'# of positive samples: {np.sum(y_train)}')\n",
    "print(f'# of negative samples: {x_train.shape[0] - np.sum(y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resampled dataset (x_train, y_train) will be used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the HPO session with Optuna\n",
    "FOLDS = 5\n",
    "SEED = 4321\n",
    "\n",
    "N_TRIALS = 100\n",
    "TIME_BUDGET = 7200\n",
    "STUDY_NAME = \"xgb-gpu01\"\n",
    "\n",
    "# ranges\n",
    "LR_LOW = 1e-3\n",
    "LR_HIGH = 1e-2\n",
    "DEPTH_LOW = 4\n",
    "DEPTH_HIGH = 10\n",
    "N_ITER_LIST = [2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000]\n",
    "GAMMA_LOW = 0.1\n",
    "GAMMA_HIGH = 5\n",
    "SUBSAMPLE_LOW = 0.1\n",
    "SUBSAMPLE_HIGH = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-16 15:07:30,109]\u001b[0m A new study created in RDB with name: xgb-gpu01\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here we define the strategy, the space for hyper-parameters we want to explore\n",
    "#\n",
    "params = {\n",
    "    \"n_estimators\": CategoricalDistribution(N_ITER_LIST),\n",
    "    \"learning_rate\": LogUniformDistribution(low=LR_LOW, high=LR_HIGH),\n",
    "    \"max_depth\": IntUniformDistribution(DEPTH_LOW, DEPTH_HIGH),\n",
    "    \"gamma\" : LogUniformDistribution(low=GAMMA_LOW, high=GAMMA_HIGH),\n",
    "    \"subsample\" : UniformDistribution(low=SUBSAMPLE_LOW, high=SUBSAMPLE_HIGH),\n",
    "    \"tree_method\": \"gpu_hist\"\n",
    "}\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "# per lista scorer sorted(sklearn.metrics.SCORERS.keys())\n",
    "tuner = ADSTuner(clf, cv=FOLDS, strategy=params, scoring=\"recall\", study_name=STUDY_NAME, n_jobs=10, random_state=SEED)\n",
    "\n",
    "tuner.tune(x_train, y_train, exit_criterion=[TimeBudget(TIME_BUDGET)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the status to see if completed\n",
    "print(f\"The tuner status is: {tuner.get_status()}\")\n",
    "\n",
    "print(f\"Remaining time is: {round(tuner.time_remaining, 1)} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_gamma</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>user_attrs_metric</th>\n",
       "      <th>user_attrs_split0_test_score</th>\n",
       "      <th>user_attrs_split1_test_score</th>\n",
       "      <th>user_attrs_split2_test_score</th>\n",
       "      <th>user_attrs_split3_test_score</th>\n",
       "      <th>user_attrs_split4_test_score</th>\n",
       "      <th>user_attrs_std_fit_time</th>\n",
       "      <th>user_attrs_std_score_time</th>\n",
       "      <th>user_attrs_std_test_score</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.441696</td>\n",
       "      <td>2022-03-16 15:50:40.278688</td>\n",
       "      <td>2022-03-16 15:56:23.493697</td>\n",
       "      <td>0 days 00:05:43.215009</td>\n",
       "      <td>4.867601</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>10</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.611177</td>\n",
       "      <td>...</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.441397</td>\n",
       "      <td>0.434414</td>\n",
       "      <td>0.435910</td>\n",
       "      <td>0.448379</td>\n",
       "      <td>0.448379</td>\n",
       "      <td>0.687555</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.005932</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.441496</td>\n",
       "      <td>2022-03-16 15:51:43.052523</td>\n",
       "      <td>2022-03-16 15:57:16.641345</td>\n",
       "      <td>0 days 00:05:33.588822</td>\n",
       "      <td>4.844744</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>10</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.585022</td>\n",
       "      <td>...</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.441397</td>\n",
       "      <td>0.436409</td>\n",
       "      <td>0.435411</td>\n",
       "      <td>0.446883</td>\n",
       "      <td>0.447382</td>\n",
       "      <td>0.365662</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.441496</td>\n",
       "      <td>2022-03-16 15:54:07.757894</td>\n",
       "      <td>2022-03-16 15:59:25.541258</td>\n",
       "      <td>0 days 00:05:17.783364</td>\n",
       "      <td>4.976931</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>10</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.611855</td>\n",
       "      <td>...</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.441397</td>\n",
       "      <td>0.434414</td>\n",
       "      <td>0.435411</td>\n",
       "      <td>0.447382</td>\n",
       "      <td>0.448878</td>\n",
       "      <td>0.610405</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.440898</td>\n",
       "      <td>2022-03-16 15:52:44.364767</td>\n",
       "      <td>2022-03-16 15:58:19.608948</td>\n",
       "      <td>0 days 00:05:35.244181</td>\n",
       "      <td>4.916737</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>10</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.617713</td>\n",
       "      <td>...</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.442394</td>\n",
       "      <td>0.436409</td>\n",
       "      <td>0.433915</td>\n",
       "      <td>0.446883</td>\n",
       "      <td>0.444888</td>\n",
       "      <td>1.115432</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.439800</td>\n",
       "      <td>2022-03-16 15:28:16.483953</td>\n",
       "      <td>2022-03-16 15:32:43.065607</td>\n",
       "      <td>0 days 00:04:26.581654</td>\n",
       "      <td>4.563597</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>10</td>\n",
       "      <td>2100</td>\n",
       "      <td>0.670141</td>\n",
       "      <td>...</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.440399</td>\n",
       "      <td>0.433915</td>\n",
       "      <td>0.434414</td>\n",
       "      <td>0.444888</td>\n",
       "      <td>0.445387</td>\n",
       "      <td>1.243047</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>0.439501</td>\n",
       "      <td>2022-03-16 16:24:00.345973</td>\n",
       "      <td>2022-03-16 16:32:20.620609</td>\n",
       "      <td>0 days 00:08:20.274636</td>\n",
       "      <td>4.320169</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>10</td>\n",
       "      <td>2700</td>\n",
       "      <td>0.662606</td>\n",
       "      <td>...</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.438404</td>\n",
       "      <td>0.433416</td>\n",
       "      <td>0.434913</td>\n",
       "      <td>0.443890</td>\n",
       "      <td>0.446883</td>\n",
       "      <td>1.526334</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.439102</td>\n",
       "      <td>2022-03-16 15:26:50.461497</td>\n",
       "      <td>2022-03-16 15:30:11.586736</td>\n",
       "      <td>0 days 00:03:21.125239</td>\n",
       "      <td>4.730048</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>10</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.103701</td>\n",
       "      <td>...</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.446883</td>\n",
       "      <td>0.438404</td>\n",
       "      <td>0.421446</td>\n",
       "      <td>0.442893</td>\n",
       "      <td>0.445885</td>\n",
       "      <td>0.259727</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>0.009307</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.439002</td>\n",
       "      <td>2022-03-16 15:22:18.197466</td>\n",
       "      <td>2022-03-16 15:28:16.467276</td>\n",
       "      <td>0 days 00:05:58.269810</td>\n",
       "      <td>4.758742</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>10</td>\n",
       "      <td>2700</td>\n",
       "      <td>0.664981</td>\n",
       "      <td>...</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.439900</td>\n",
       "      <td>0.430424</td>\n",
       "      <td>0.430923</td>\n",
       "      <td>0.447382</td>\n",
       "      <td>0.446384</td>\n",
       "      <td>0.282691</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.438903</td>\n",
       "      <td>2022-03-16 15:21:22.200401</td>\n",
       "      <td>2022-03-16 15:29:39.502240</td>\n",
       "      <td>0 days 00:08:17.301839</td>\n",
       "      <td>4.348594</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>10</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.617439</td>\n",
       "      <td>...</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.438404</td>\n",
       "      <td>0.434414</td>\n",
       "      <td>0.432918</td>\n",
       "      <td>0.443392</td>\n",
       "      <td>0.445387</td>\n",
       "      <td>0.619329</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>0.438903</td>\n",
       "      <td>2022-03-16 16:28:30.141041</td>\n",
       "      <td>2022-03-16 16:35:41.828237</td>\n",
       "      <td>0 days 00:07:11.687196</td>\n",
       "      <td>4.496039</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>9</td>\n",
       "      <td>2700</td>\n",
       "      <td>0.660533</td>\n",
       "      <td>...</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.439900</td>\n",
       "      <td>0.432918</td>\n",
       "      <td>0.431920</td>\n",
       "      <td>0.444389</td>\n",
       "      <td>0.445387</td>\n",
       "      <td>1.378407</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.005616</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "40      40  0.441696 2022-03-16 15:50:40.278688 2022-03-16 15:56:23.493697   \n",
       "41      41  0.441496 2022-03-16 15:51:43.052523 2022-03-16 15:57:16.641345   \n",
       "44      44  0.441496 2022-03-16 15:54:07.757894 2022-03-16 15:59:25.541258   \n",
       "42      42  0.440898 2022-03-16 15:52:44.364767 2022-03-16 15:58:19.608948   \n",
       "24      24  0.439800 2022-03-16 15:28:16.483953 2022-03-16 15:32:43.065607   \n",
       "71      71  0.439501 2022-03-16 16:24:00.345973 2022-03-16 16:32:20.620609   \n",
       "23      23  0.439102 2022-03-16 15:26:50.461497 2022-03-16 15:30:11.586736   \n",
       "20      20  0.439002 2022-03-16 15:22:18.197466 2022-03-16 15:28:16.467276   \n",
       "19      19  0.438903 2022-03-16 15:21:22.200401 2022-03-16 15:29:39.502240   \n",
       "74      74  0.438903 2022-03-16 16:28:30.141041 2022-03-16 16:35:41.828237   \n",
       "\n",
       "                 duration  params_gamma  params_learning_rate  \\\n",
       "40 0 days 00:05:43.215009      4.867601              0.003555   \n",
       "41 0 days 00:05:33.588822      4.844744              0.003688   \n",
       "44 0 days 00:05:17.783364      4.976931              0.003768   \n",
       "42 0 days 00:05:35.244181      4.916737              0.003616   \n",
       "24 0 days 00:04:26.581654      4.563597              0.005158   \n",
       "71 0 days 00:08:20.274636      4.320169              0.002866   \n",
       "23 0 days 00:03:21.125239      4.730048              0.003669   \n",
       "20 0 days 00:05:58.269810      4.758742              0.003632   \n",
       "19 0 days 00:08:17.301839      4.348594              0.002886   \n",
       "74 0 days 00:07:11.687196      4.496039              0.002844   \n",
       "\n",
       "    params_max_depth  params_n_estimators  params_subsample  ...  \\\n",
       "40                10                 2900          0.611177  ...   \n",
       "41                10                 2900          0.585022  ...   \n",
       "44                10                 2900          0.611855  ...   \n",
       "42                10                 2900          0.617713  ...   \n",
       "24                10                 2100          0.670141  ...   \n",
       "71                10                 2700          0.662606  ...   \n",
       "23                10                 2900          0.103701  ...   \n",
       "20                10                 2700          0.664981  ...   \n",
       "19                10                 2900          0.617439  ...   \n",
       "74                 9                 2700          0.660533  ...   \n",
       "\n",
       "   user_attrs_metric  user_attrs_split0_test_score  \\\n",
       "40            recall                      0.441397   \n",
       "41            recall                      0.441397   \n",
       "44            recall                      0.441397   \n",
       "42            recall                      0.442394   \n",
       "24            recall                      0.440399   \n",
       "71            recall                      0.438404   \n",
       "23            recall                      0.446883   \n",
       "20            recall                      0.439900   \n",
       "19            recall                      0.438404   \n",
       "74            recall                      0.439900   \n",
       "\n",
       "    user_attrs_split1_test_score  user_attrs_split2_test_score  \\\n",
       "40                      0.434414                      0.435910   \n",
       "41                      0.436409                      0.435411   \n",
       "44                      0.434414                      0.435411   \n",
       "42                      0.436409                      0.433915   \n",
       "24                      0.433915                      0.434414   \n",
       "71                      0.433416                      0.434913   \n",
       "23                      0.438404                      0.421446   \n",
       "20                      0.430424                      0.430923   \n",
       "19                      0.434414                      0.432918   \n",
       "74                      0.432918                      0.431920   \n",
       "\n",
       "   user_attrs_split3_test_score  user_attrs_split4_test_score  \\\n",
       "40                     0.448379                      0.448379   \n",
       "41                     0.446883                      0.447382   \n",
       "44                     0.447382                      0.448878   \n",
       "42                     0.446883                      0.444888   \n",
       "24                     0.444888                      0.445387   \n",
       "71                     0.443890                      0.446883   \n",
       "23                     0.442893                      0.445885   \n",
       "20                     0.447382                      0.446384   \n",
       "19                     0.443392                      0.445387   \n",
       "74                     0.444389                      0.445387   \n",
       "\n",
       "    user_attrs_std_fit_time  user_attrs_std_score_time  \\\n",
       "40                 0.687555                   0.003846   \n",
       "41                 0.365662                   0.005398   \n",
       "44                 0.610405                   0.003014   \n",
       "42                 1.115432                   0.001861   \n",
       "24                 1.243047                   0.002495   \n",
       "71                 1.526334                   0.002947   \n",
       "23                 0.259727                   0.003961   \n",
       "20                 0.282691                   0.001675   \n",
       "19                 0.619329                   0.002228   \n",
       "74                 1.378407                   0.004990   \n",
       "\n",
       "    user_attrs_std_test_score     state  \n",
       "40                   0.005932  COMPLETE  \n",
       "41                   0.005031  COMPLETE  \n",
       "44                   0.005938  COMPLETE  \n",
       "42                   0.004958  COMPLETE  \n",
       "24                   0.004921  COMPLETE  \n",
       "71                   0.005158  COMPLETE  \n",
       "23                   0.009307  COMPLETE  \n",
       "20                   0.007272  COMPLETE  \n",
       "19                   0.004866  COMPLETE  \n",
       "74                   0.005616  COMPLETE  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look only at completed trials, sorted with best on top. Metric chosen is in the value col.\n",
    "result_df = tuner.trials[tuner.trials[\"state\"] == \"COMPLETE\"].sort_values(\n",
    "    by=[\"value\"], ascending=False\n",
    ")\n",
    "\n",
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADSTuner session results:\n",
      "ADSTuner has launched 99 trials\n",
      "ADSTuner has completed 99 trials\n",
      "\n",
      "The best trial is the #: 40\n",
      "Parameters for the best trial are: {'gamma': 4.867601210093122, 'learning_rate': 0.00355503955960397, 'max_depth': 10, 'n_estimators': 2900, 'subsample': 0.6111768133956392, 'tree_method': 'gpu_hist'}\n",
      "The metric used to optimize is: recall\n",
      "The best score is: 0.4417\n"
     ]
    }
   ],
   "source": [
    "def show_tuner_results(tuner):\n",
    "\n",
    "    # to count completed\n",
    "    result_df = tuner.trials[tuner.trials[\"state\"] == \"COMPLETE\"].sort_values(\n",
    "        by=[\"value\"], ascending=False\n",
    "    )\n",
    "\n",
    "    print(\"ADSTuner session results:\")\n",
    "    print(f\"ADSTuner has launched {tuner.trials.shape[0]} trials\")\n",
    "    print(f\"ADSTuner has completed {result_df.shape[0]} trials\")\n",
    "    print()\n",
    "    print(f\"The best trial is the #: {tuner.best_index}\")\n",
    "    print(f\"Parameters for the best trial are: {tuner.best_params}\")\n",
    "    print(f\"The metric used to optimize is: {tuner.scoring_name}\")\n",
    "    print(f\"The best score is: {round(tuner.best_score, 4)}\")\n",
    "    \n",
    "show_tuner_results(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf = xgb.XGBClassifier(**tuner.best_params)\n",
    "\n",
    "# addestro e valuto su train e su validation set\n",
    "clf.fit(x_train, y_train,\n",
    "        eval_set=[(x_train, y_train)],\n",
    "        eval_metric='auc', verbose=100)\n",
    "\n",
    "print()\n",
    "\n",
    "evals_result = clf.evals_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OK, consider that the slightly higher AUC is due to the fact here we're evaluating also on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc(train_hist):\n",
    "    plt.figure(figsize=(9,6))\n",
    "    \n",
    "    plt.plot(train_hist, label='Training AUC')\n",
    "    plt.title('AUC')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('auc')\n",
    "    plt.xlabel('n_estimator')\n",
    "    plt.grid(True)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = evals_result['validation_0']['auc']\n",
    "\n",
    "plot_auc(train_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy on full dataset\n",
    "y_pred = clf.predict(x_train_full)\n",
    "\n",
    "# not really needed for XGBoost\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_train_full, predictions)\n",
    "\n",
    "print(\"Accuracy on train set: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute confusion matrix on full dataset\n",
    "cm = confusion_matrix(y_train_full, predictions)\n",
    "\n",
    "# plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpretability\n",
    "# feature importance\n",
    "# plot\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title('Features importance')\n",
    "sns.barplot(x=data_full.drop(TARGET, axis = 1).columns, y=clf.feature_importances_)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of FN is rather high but using recall things get better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the TEST set (for submission to Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on test set\n",
    "orig_test = pd.read_csv('cs-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inpute missing values, add the two indicator columns\n",
    "MONTHLY_INC_MEDIAN = 5400.\n",
    "N_OF_DEP_MODE = 0\n",
    "\n",
    "orig_test['isna_mi'] = 0\n",
    "orig_test.loc[orig_test[COL1_MISSING].isna(), 'isna_mi'] = 1\n",
    "orig_test.loc[orig_test[COL1_MISSING].isna(), COL1_MISSING] = MONTHLY_INC_MEDIAN\n",
    "\n",
    "orig_test['isna_nod'] = 0\n",
    "orig_test.loc[orig_test[COL2_MISSING].isna(), 'isna_nod'] = 1\n",
    "orig_test.loc[orig_test[COL2_MISSING].isna(), COL2_MISSING] = N_OF_DEP_MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test = orig_test[ind_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test = orig_test.drop(ind_col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COL_NAME = 'Unnamed: 0'\n",
    "xorig_test = orig_test.drop(ID_COL_NAME, axis = 1)\n",
    "xorig_test = xorig_test.drop(TARGET, axis = 1)\n",
    "\n",
    "x_test = xorig_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggiungi qui lo scaling !!!\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "# riaggiunge le colonne indicatore\n",
    "x_test_scaled = np.c_[x_test_scaled, ind_test]\n",
    "\n",
    "assert x_test_scaled.shape[1] == N_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do predictions on test set (no shuffle !)\n",
    "y_pred = clf.predict_proba(x_test)\n",
    "\n",
    "# y_pred contiene le probabilitÃ \n",
    "y_pred = y_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepara il csv per la submission\n",
    "result_dict = {\"Id\": orig_test[ID_COL_NAME].values,\n",
    "              'Probability': y_pred}\n",
    "\n",
    "FILE_SUB = 'submission36.csv'\n",
    "\n",
    "# build a dataframe and save to csv\n",
    "result_df = pd.DataFrame(result_dict)\n",
    "\n",
    "result_df.to_csv(FILE_SUB, index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Modela and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model: uso un formato semplice: pkl\n",
    "pickle.dump(clf, open(\"credit-scoring.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvo anche lo scaler\n",
    "pickle.dump(scaler, open(\"scaler.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the model\n",
    "loaded_model = pickle.load(open(\"credit-scoring.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the scaler\n",
    "loaded_scaler = pickle.load(open(\"scaler.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for online predictions\n",
    "# input are given as a numpy array, with no missing fields, but we need to add the two indicator columns\n",
    "x_input = np.array([[1,2,3,4,5,6,7,8,9,10],\n",
    "                   [1,2,3,4,5,6,7,8,9,10],\n",
    "                   [1,2,3,4,5,6,7,8,9,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlli\n",
    "assert x_input.shape[1] == 10\n",
    "# check there are no null\n",
    "assert np.sum(np.isnan(x_input)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "x_input_scaled = loaded_scaler.transform(x_input)\n",
    "\n",
    "# add two columns with 0\n",
    "x_add = np.zeros((x_input.shape[0], 2))\n",
    "x_input_scaled = np.c_[x_input_scaled, x_add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(x_input_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[TARGET].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
