{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "import ads\n",
    "\n",
    "# to use ADSTuner\n",
    "from ads.hpo.search_cv import ADSTuner\n",
    "from ads.hpo.stopping_criterion import *\n",
    "from ads.hpo.distributions import *\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# for undersampling the negative class\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.8\n"
     ]
    }
   ],
   "source": [
    "# check the ADS version\n",
    "print(ads.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants\n",
    "N_ESTIMATORS = 1000\n",
    "# numero di features compreso le due colonne indicatore aggiunte\n",
    "N_FEATURES = 12\n",
    "\n",
    "# nome della colonna con le label\n",
    "TARGET = 'SeriousDlqin2yrs'\n",
    "\n",
    "# colonne con missing values\n",
    "COL1_MISSING = 'MonthlyIncome'\n",
    "COL2_MISSING = 'NumberOfDependents'\n",
    "\n",
    "# nomi delle due colonne indicator (valgono 1 laddove il dato Ã¨ inputato)\n",
    "IND1 = 'isna_mi'\n",
    "IND2 = 'isna_nod'\n",
    "\n",
    "ind_col = [IND1, IND2]\n",
    "\n",
    "# prese da stats sul train test, usate per inputare i missing values su COL1 e CL2\n",
    "MONTHLY_INC_MEDIAN = 5400.0\n",
    "N_OF_DEP_MODE = 0\n",
    "\n",
    "# ratio minority samples/majority\n",
    "RATIO = 1./5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full, not undersampled\n",
    "data_full = pd.read_csv('cs-training-nonull.csv')\n",
    "\n",
    "# remove unneeded\n",
    "data_full = data_full.drop('id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metto da parte le due colonne indicatori\n",
    "ind_train = data_full[ind_col].values\n",
    "\n",
    "data_full = data_full.drop(ind_col, axis = 1)\n",
    "\n",
    "# estrae X: matrice features ed y, labels\n",
    "y_train_full = data_full[TARGET].values\n",
    "x_train_full = data_full.drop(TARGET, axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepara lo scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# calcola i parametri di scaling solo sul train set\n",
    "scaler.fit(x_train_full)\n",
    "\n",
    "# scalo tutto tranne che le due colonne indicatore\n",
    "x_train_full_scaled = scaler.transform(x_train_full)\n",
    "\n",
    "# riaggiungo gli indicatori (che non vengono scalati)\n",
    "x_train_full_scaled = np.c_[x_train_full_scaled, ind_train]\n",
    "\n",
    "# check\n",
    "assert x_train_full_scaled.shape[1] == N_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples in full dataset: 150000\n"
     ]
    }
   ],
   "source": [
    "print(f'# of samples in full dataset: {x_train_full_scaled.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the undersampling of the negative class\n",
    "rus = RandomUnderSampler(sampling_strategy=RATIO, random_state=4321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = rus.fit_resample(x_train_full_scaled, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples in resampled dataset: 60156\n"
     ]
    }
   ],
   "source": [
    "print(f'# of samples in resampled dataset: {x_train.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of positive samples: 10026\n",
      "# of negative samples: 50130\n"
     ]
    }
   ],
   "source": [
    "# check ratio of classes\n",
    "print(f'# of positive samples: {np.sum(y_train)}')\n",
    "print(f'# of negative samples: {x_train.shape[0] - np.sum(y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the HPO session with Optuna\n",
    "FOLDS = 5\n",
    "SEED = 4321\n",
    "\n",
    "N_TRIALS = 100\n",
    "TIME_BUDGET = 7200\n",
    "STUDY_NAME = \"xgb01\"\n",
    "\n",
    "# ranges\n",
    "LR_LOW = 1e-3\n",
    "LR_HIGH = 1e-2\n",
    "DEPTH_LOW = 4\n",
    "DEPTH_HIGH = 8\n",
    "N_ITER_LIST = [600, 700, 800, 900, 1000, 1100, 1200, 1300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-14 18:42:26,390]\u001b[0m A new study created in RDB with name: xgb01\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here we define the strategy, the space for hyper-parameters we want to explore\n",
    "#\n",
    "params = {\n",
    "    \"n_estimators\": CategoricalDistribution(N_ITER_LIST),\n",
    "    \"learning_rate\": LogUniformDistribution(low=LR_LOW, high=LR_HIGH),\n",
    "    \"max_depth\": IntUniformDistribution(DEPTH_LOW, DEPTH_HIGH),\n",
    "}\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "# per lista scorer sorted(sklearn.metrics.SCORERS.keys())\n",
    "tuner = ADSTuner(clf, cv=FOLDS, strategy=params, scoring=\"roc_auc\", study_name=STUDY_NAME, n_jobs=6)\n",
    "\n",
    "tuner.tune(x_train, y_train, exit_criterion=[TimeBudget(TIME_BUDGET)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tuner status is: State.RUNNING\n",
      "Remaining time is: 6684.0 sec.\n"
     ]
    }
   ],
   "source": [
    "# get the status to see if completed\n",
    "print(f\"The tuner status is: {tuner.get_status()}\")\n",
    "\n",
    "print(f\"Remaining time is: {round(tuner.time_remaining, 1)} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>user_attrs_mean_fit_time</th>\n",
       "      <th>user_attrs_mean_score_time</th>\n",
       "      <th>...</th>\n",
       "      <th>user_attrs_metric</th>\n",
       "      <th>user_attrs_split0_test_score</th>\n",
       "      <th>user_attrs_split1_test_score</th>\n",
       "      <th>user_attrs_split2_test_score</th>\n",
       "      <th>user_attrs_split3_test_score</th>\n",
       "      <th>user_attrs_split4_test_score</th>\n",
       "      <th>user_attrs_std_fit_time</th>\n",
       "      <th>user_attrs_std_score_time</th>\n",
       "      <th>user_attrs_std_test_score</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0.865477</td>\n",
       "      <td>2022-03-14 19:15:34.166132</td>\n",
       "      <td>2022-03-14 19:20:15.688278</td>\n",
       "      <td>0 days 00:04:41.522146</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>4</td>\n",
       "      <td>1200</td>\n",
       "      <td>56.213223</td>\n",
       "      <td>0.040291</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.864384</td>\n",
       "      <td>0.860433</td>\n",
       "      <td>0.866017</td>\n",
       "      <td>0.864576</td>\n",
       "      <td>0.871974</td>\n",
       "      <td>14.187219</td>\n",
       "      <td>0.020774</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.865447</td>\n",
       "      <td>2022-03-14 19:15:08.777743</td>\n",
       "      <td>2022-03-14 19:20:01.041820</td>\n",
       "      <td>0 days 00:04:52.264077</td>\n",
       "      <td>0.008394</td>\n",
       "      <td>4</td>\n",
       "      <td>1200</td>\n",
       "      <td>58.361284</td>\n",
       "      <td>0.040683</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.864346</td>\n",
       "      <td>0.860490</td>\n",
       "      <td>0.865864</td>\n",
       "      <td>0.864479</td>\n",
       "      <td>0.872055</td>\n",
       "      <td>14.993363</td>\n",
       "      <td>0.014331</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.865420</td>\n",
       "      <td>2022-03-14 19:05:21.732425</td>\n",
       "      <td>2022-03-14 19:09:05.619339</td>\n",
       "      <td>0 days 00:03:43.886914</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>4</td>\n",
       "      <td>1200</td>\n",
       "      <td>44.700664</td>\n",
       "      <td>0.032901</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.864327</td>\n",
       "      <td>0.860497</td>\n",
       "      <td>0.865925</td>\n",
       "      <td>0.864451</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0.408484</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.865380</td>\n",
       "      <td>2022-03-14 19:04:46.994972</td>\n",
       "      <td>2022-03-14 19:08:31.409141</td>\n",
       "      <td>0 days 00:03:44.414169</td>\n",
       "      <td>0.007625</td>\n",
       "      <td>4</td>\n",
       "      <td>1200</td>\n",
       "      <td>44.808593</td>\n",
       "      <td>0.030716</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.864163</td>\n",
       "      <td>0.860499</td>\n",
       "      <td>0.865923</td>\n",
       "      <td>0.864508</td>\n",
       "      <td>0.871805</td>\n",
       "      <td>0.415131</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0.865374</td>\n",
       "      <td>2022-03-14 19:17:50.359384</td>\n",
       "      <td>2022-03-14 19:21:16.233045</td>\n",
       "      <td>0 days 00:03:25.873661</td>\n",
       "      <td>0.008329</td>\n",
       "      <td>4</td>\n",
       "      <td>1100</td>\n",
       "      <td>41.097793</td>\n",
       "      <td>0.027783</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.864168</td>\n",
       "      <td>0.860480</td>\n",
       "      <td>0.865927</td>\n",
       "      <td>0.864373</td>\n",
       "      <td>0.871922</td>\n",
       "      <td>0.802906</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.003730</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.865370</td>\n",
       "      <td>2022-03-14 19:05:47.642608</td>\n",
       "      <td>2022-03-14 19:09:33.205618</td>\n",
       "      <td>0 days 00:03:45.563010</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>4</td>\n",
       "      <td>1200</td>\n",
       "      <td>45.037852</td>\n",
       "      <td>0.031325</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.864243</td>\n",
       "      <td>0.860521</td>\n",
       "      <td>0.865800</td>\n",
       "      <td>0.864424</td>\n",
       "      <td>0.871862</td>\n",
       "      <td>0.275470</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.865361</td>\n",
       "      <td>2022-03-14 19:00:47.969233</td>\n",
       "      <td>2022-03-14 19:05:47.842584</td>\n",
       "      <td>0 days 00:04:59.873351</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>5</td>\n",
       "      <td>1300</td>\n",
       "      <td>59.895556</td>\n",
       "      <td>0.036156</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.864396</td>\n",
       "      <td>0.860141</td>\n",
       "      <td>0.865449</td>\n",
       "      <td>0.864629</td>\n",
       "      <td>0.872188</td>\n",
       "      <td>0.473733</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.865352</td>\n",
       "      <td>2022-03-14 18:57:11.598903</td>\n",
       "      <td>2022-03-14 19:01:49.973163</td>\n",
       "      <td>0 days 00:04:38.374260</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>5</td>\n",
       "      <td>1200</td>\n",
       "      <td>55.595457</td>\n",
       "      <td>0.036831</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.864473</td>\n",
       "      <td>0.860012</td>\n",
       "      <td>0.865259</td>\n",
       "      <td>0.864683</td>\n",
       "      <td>0.872332</td>\n",
       "      <td>0.131069</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.865342</td>\n",
       "      <td>2022-03-14 18:57:44.381019</td>\n",
       "      <td>2022-03-14 19:01:15.252882</td>\n",
       "      <td>0 days 00:03:30.871863</td>\n",
       "      <td>0.009654</td>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>42.097937</td>\n",
       "      <td>0.032530</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.864211</td>\n",
       "      <td>0.860217</td>\n",
       "      <td>0.865536</td>\n",
       "      <td>0.864603</td>\n",
       "      <td>0.872145</td>\n",
       "      <td>0.155584</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.865333</td>\n",
       "      <td>2022-03-14 19:00:49.808633</td>\n",
       "      <td>2022-03-14 19:05:47.625723</td>\n",
       "      <td>0 days 00:04:57.817090</td>\n",
       "      <td>0.009802</td>\n",
       "      <td>5</td>\n",
       "      <td>1300</td>\n",
       "      <td>59.483752</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.864674</td>\n",
       "      <td>0.859673</td>\n",
       "      <td>0.865336</td>\n",
       "      <td>0.864686</td>\n",
       "      <td>0.872294</td>\n",
       "      <td>0.350686</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "50      50  0.865477 2022-03-14 19:15:34.166132 2022-03-14 19:20:15.688278   \n",
       "49      49  0.865447 2022-03-14 19:15:08.777743 2022-03-14 19:20:01.041820   \n",
       "35      35  0.865420 2022-03-14 19:05:21.732425 2022-03-14 19:09:05.619339   \n",
       "34      34  0.865380 2022-03-14 19:04:46.994972 2022-03-14 19:08:31.409141   \n",
       "51      51  0.865374 2022-03-14 19:17:50.359384 2022-03-14 19:21:16.233045   \n",
       "36      36  0.865370 2022-03-14 19:05:47.642608 2022-03-14 19:09:33.205618   \n",
       "28      28  0.865361 2022-03-14 19:00:47.969233 2022-03-14 19:05:47.842584   \n",
       "25      25  0.865352 2022-03-14 18:57:11.598903 2022-03-14 19:01:49.973163   \n",
       "27      27  0.865342 2022-03-14 18:57:44.381019 2022-03-14 19:01:15.252882   \n",
       "29      29  0.865333 2022-03-14 19:00:49.808633 2022-03-14 19:05:47.625723   \n",
       "\n",
       "                 duration  params_learning_rate  params_max_depth  \\\n",
       "50 0 days 00:04:41.522146              0.008492                 4   \n",
       "49 0 days 00:04:52.264077              0.008394                 4   \n",
       "35 0 days 00:03:43.886914              0.008013                 4   \n",
       "34 0 days 00:03:44.414169              0.007625                 4   \n",
       "51 0 days 00:03:25.873661              0.008329                 4   \n",
       "36 0 days 00:03:45.563010              0.007832                 4   \n",
       "28 0 days 00:04:59.873351              0.008288                 5   \n",
       "25 0 days 00:04:38.374260              0.009434                 5   \n",
       "27 0 days 00:03:30.871863              0.009654                 5   \n",
       "29 0 days 00:04:57.817090              0.009802                 5   \n",
       "\n",
       "    params_n_estimators  user_attrs_mean_fit_time  user_attrs_mean_score_time  \\\n",
       "50                 1200                 56.213223                    0.040291   \n",
       "49                 1200                 58.361284                    0.040683   \n",
       "35                 1200                 44.700664                    0.032901   \n",
       "34                 1200                 44.808593                    0.030716   \n",
       "51                 1100                 41.097793                    0.027783   \n",
       "36                 1200                 45.037852                    0.031325   \n",
       "28                 1300                 59.895556                    0.036156   \n",
       "25                 1200                 55.595457                    0.036831   \n",
       "27                  900                 42.097937                    0.032530   \n",
       "29                 1300                 59.483752                    0.035667   \n",
       "\n",
       "    ...  user_attrs_metric user_attrs_split0_test_score  \\\n",
       "50  ...            roc_auc                     0.864384   \n",
       "49  ...            roc_auc                     0.864346   \n",
       "35  ...            roc_auc                     0.864327   \n",
       "34  ...            roc_auc                     0.864163   \n",
       "51  ...            roc_auc                     0.864168   \n",
       "36  ...            roc_auc                     0.864243   \n",
       "28  ...            roc_auc                     0.864396   \n",
       "25  ...            roc_auc                     0.864473   \n",
       "27  ...            roc_auc                     0.864211   \n",
       "29  ...            roc_auc                     0.864674   \n",
       "\n",
       "    user_attrs_split1_test_score  user_attrs_split2_test_score  \\\n",
       "50                      0.860433                      0.866017   \n",
       "49                      0.860490                      0.865864   \n",
       "35                      0.860497                      0.865925   \n",
       "34                      0.860499                      0.865923   \n",
       "51                      0.860480                      0.865927   \n",
       "36                      0.860521                      0.865800   \n",
       "28                      0.860141                      0.865449   \n",
       "25                      0.860012                      0.865259   \n",
       "27                      0.860217                      0.865536   \n",
       "29                      0.859673                      0.865336   \n",
       "\n",
       "    user_attrs_split3_test_score  user_attrs_split4_test_score  \\\n",
       "50                      0.864576                      0.871974   \n",
       "49                      0.864479                      0.872055   \n",
       "35                      0.864451                      0.871900   \n",
       "34                      0.864508                      0.871805   \n",
       "51                      0.864373                      0.871922   \n",
       "36                      0.864424                      0.871862   \n",
       "28                      0.864629                      0.872188   \n",
       "25                      0.864683                      0.872332   \n",
       "27                      0.864603                      0.872145   \n",
       "29                      0.864686                      0.872294   \n",
       "\n",
       "    user_attrs_std_fit_time  user_attrs_std_score_time  \\\n",
       "50                14.187219                   0.020774   \n",
       "49                14.993363                   0.014331   \n",
       "35                 0.408484                   0.002534   \n",
       "34                 0.415131                   0.002147   \n",
       "51                 0.802906                   0.001606   \n",
       "36                 0.275470                   0.001943   \n",
       "28                 0.473733                   0.001226   \n",
       "25                 0.131069                   0.003997   \n",
       "27                 0.155584                   0.001305   \n",
       "29                 0.350686                   0.001221   \n",
       "\n",
       "    user_attrs_std_test_score     state  \n",
       "50                   0.003740  COMPLETE  \n",
       "49                   0.003757  COMPLETE  \n",
       "35                   0.003704  COMPLETE  \n",
       "34                   0.003678  COMPLETE  \n",
       "51                   0.003730  COMPLETE  \n",
       "36                   0.003688  COMPLETE  \n",
       "28                   0.003882  COMPLETE  \n",
       "25                   0.003961  COMPLETE  \n",
       "27                   0.003858  COMPLETE  \n",
       "29                   0.004034  COMPLETE  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look only at completed trials, sorted with best on top. Metric chosen is in the value col.\n",
    "result_df = tuner.trials[tuner.trials[\"state\"] == \"COMPLETE\"].sort_values(\n",
    "    by=[\"value\"], ascending=False\n",
    ")\n",
    "\n",
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADSTuner session results:\n",
      "ADSTuner has launched 58 trials\n",
      "ADSTuner has completed 52 trials\n",
      "\n",
      "The best trial is the #: 50\n",
      "Parameters for the best trial are: {'learning_rate': 0.008491587447830361, 'max_depth': 4, 'n_estimators': 1200}\n",
      "The metric used to optimize is: roc_auc\n",
      "The best score is: 0.8655\n"
     ]
    }
   ],
   "source": [
    "def show_tuner_results(tuner):\n",
    "\n",
    "    # to count completed\n",
    "    result_df = tuner.trials[tuner.trials[\"state\"] == \"COMPLETE\"].sort_values(\n",
    "        by=[\"value\"], ascending=False\n",
    "    )\n",
    "\n",
    "    print(\"ADSTuner session results:\")\n",
    "    print(f\"ADSTuner has launched {tuner.trials.shape[0]} trials\")\n",
    "    print(f\"ADSTuner has completed {result_df.shape[0]} trials\")\n",
    "    print()\n",
    "    print(f\"The best trial is the #: {tuner.best_index}\")\n",
    "    print(f\"Parameters for the best trial are: {tuner.best_params}\")\n",
    "    print(f\"The metric used to optimize is: {tuner.scoring_name}\")\n",
    "    print(f\"The best score is: {round(tuner.best_score, 4)}\")\n",
    "    \n",
    "show_tuner_results(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.83249\n",
      "[100]\tvalidation_0-auc:0.84925\n",
      "[200]\tvalidation_0-auc:0.85583\n",
      "[300]\tvalidation_0-auc:0.86053\n",
      "[400]\tvalidation_0-auc:0.86350\n",
      "[500]\tvalidation_0-auc:0.86660\n",
      "[600]\tvalidation_0-auc:0.86891\n",
      "[700]\tvalidation_0-auc:0.87065\n",
      "[800]\tvalidation_0-auc:0.87195\n",
      "[900]\tvalidation_0-auc:0.87289\n",
      "[1000]\tvalidation_0-auc:0.87373\n",
      "[1100]\tvalidation_0-auc:0.87443\n",
      "[1199]\tvalidation_0-auc:0.87509\n",
      "\n",
      "CPU times: user 2h 12min 5s, sys: 1min 30s, total: 2h 13min 36s\n",
      "Wall time: 5min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = xgb.XGBClassifier(**tuner.best_params)\n",
    "\n",
    "# addestro e valuto su train e su validation set\n",
    "clf.fit(x_train, y_train,\n",
    "        eval_set=[(x_train, y_train)],\n",
    "        eval_metric='auc', verbose=100)\n",
    "\n",
    "print()\n",
    "\n",
    "evals_result = clf.evals_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OK, consider that the slightly higher AUC is due to the fact here we're evaluating also on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc(train_hist):\n",
    "    plt.figure(figsize=(9,6))\n",
    "    \n",
    "    plt.plot(train_hist, label='Training AUC')\n",
    "    plt.title('AUC')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('auc')\n",
    "    plt.xlabel('n_estimator')\n",
    "    plt.grid(True)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = evals_result['validation_0']['auc']\n",
    "\n",
    "plot_auc(train_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 92.75%\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy on full dataset\n",
    "y_pred = clf.predict(x_train_full_scaled)\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_train_full, predictions)\n",
    "\n",
    "print(\"Accuracy on train set: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134608, 5366, 5503, 4523)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute confusion matrix on full dataset\n",
    "tn, fp, fn, tp = confusion_matrix(y_train_full, predictions).ravel()\n",
    "\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the TEST set (for submission to Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on test set\n",
    "orig_test = pd.read_csv('cs-test.csv')\n",
    "\n",
    "# inpute missing values, add the two indicator columns\n",
    "orig_test['isna_mi'] = 0\n",
    "orig_test.loc[orig_test[COL1_MISSING].isna(), 'isna_mi'] = 1\n",
    "orig_test.loc[orig_test[COL1_MISSING].isna(), COL1_MISSING] = MONTHLY_INC_MEDIAN\n",
    "\n",
    "orig_test['isna_nod'] = 0\n",
    "orig_test.loc[orig_test[COL2_MISSING].isna(), 'isna_nod'] = 1\n",
    "orig_test.loc[orig_test[COL2_MISSING].isna(), COL2_MISSING] = N_OF_DEP_MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test = orig_test[ind_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test = orig_test.drop(ind_col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COL_NAME = 'Unnamed: 0'\n",
    "xorig_test = orig_test.drop(ID_COL_NAME, axis = 1)\n",
    "xorig_test = xorig_test.drop(TARGET, axis = 1)\n",
    "\n",
    "x_test = xorig_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggiungi qui lo scaling !!!\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "# riaggiunge le colonne indicatore\n",
    "x_test_scaled = np.c_[x_test_scaled, ind_test]\n",
    "\n",
    "assert x_test_scaled.shape[1] == N_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do predictions on test set (no shuffle !)\n",
    "y_pred = clf.predict_proba(x_test_scaled)\n",
    "\n",
    "# y_pred contiene le probabilitÃ \n",
    "y_pred = y_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepara il csv per la submission\n",
    "result_dict = {\"Id\": orig_test[ID_COL_NAME].values,\n",
    "              'Probability': y_pred}\n",
    "\n",
    "FILE_SUB = 'submission25.csv'\n",
    "\n",
    "# build a dataframe and save to csv\n",
    "result_df = pd.DataFrame(result_dict)\n",
    "\n",
    "result_df.to_csv(FILE_SUB, index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Modela and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model: uso un formato semplice: pkl\n",
    "pickle.dump(clf, open(\"credit-scoring.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvo anche lo scaler\n",
    "pickle.dump(scaler, open(\"scaler.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the model\n",
    "loaded_model = pickle.load(open(\"credit-scoring.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the scaler\n",
    "loaded_scaler = pickle.load(open(\"scaler.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for online predictions\n",
    "# input are given as a numpy array, with no missing fields, but we need to add the two indicator columns\n",
    "x_input = np.array([[1,2,3,4,5,6,7,8,9,10],\n",
    "                   [1,2,3,4,5,6,7,8,9,10],\n",
    "                   [1,2,3,4,5,6,7,8,9,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlli\n",
    "assert x_input.shape[1] == 10\n",
    "# check there are no null\n",
    "assert np.sum(np.isnan(x_input)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "x_input_scaled = loaded_scaler.transform(x_input)\n",
    "\n",
    "# add two columns with 0\n",
    "x_add = np.zeros((x_input.shape[0], 2))\n",
    "x_input_scaled = np.c_[x_input_scaled, x_add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(x_input_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[TARGET].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_cpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_cpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
