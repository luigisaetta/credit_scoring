{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with ADSTuner for HPO\n",
    "\n",
    "* Imblearn for undersampling of negative class\n",
    "* ADSTuner for HPO\n",
    "* tuning on more parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "import ads\n",
    "\n",
    "# to use ADSTuner\n",
    "from ads.hpo.search_cv import ADSTuner\n",
    "from ads.hpo.stopping_criterion import *\n",
    "from ads.hpo.distributions import *\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# for undersampling the negative class\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# my utils.py\n",
    "from utils import train_encoders, apply_encoders\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.4\n"
     ]
    }
   ],
   "source": [
    "# check the ADS version\n",
    "print(ads.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants\n",
    "SEED = 4321\n",
    "\n",
    "# number of features (with the two indicator cols)\n",
    "N_FEATURES = 12\n",
    "\n",
    "# name of col with label\n",
    "TARGET = 'SeriousDlqin2yrs'\n",
    "\n",
    "# cols with missing values\n",
    "COL1_MISSING = 'MonthlyIncome'\n",
    "COL2_MISSING = 'NumberOfDependents'\n",
    "\n",
    "# nomi delle due colonne indicator (valgono 1 laddove il dato è inputato)\n",
    "IND1 = 'isna_mi'\n",
    "IND2 = 'isna_nod'\n",
    "\n",
    "ind_col = [IND1, IND2]\n",
    "\n",
    "COLS_TO_DROP = ['id']\n",
    "\n",
    "# for undersampling to make the dataset more balanced\n",
    "# ratio minority samples/majority\n",
    "RATIO = 1./5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset, not undersampled\n",
    "data_full = pd.read_csv('cs-training-nonull.csv')\n",
    "\n",
    "# remove unneeded cols\n",
    "data_full = data_full.drop(COLS_TO_DROP, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['age','NumberOfTime30-59DaysPastDueNotWorse',\n",
    "               'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n",
    "               'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n",
    "               'NumberOfDependents']\n",
    "num_cols = ['RevolvingUtilizationOfUnsecuredLines', 'DebtRatio', 'MonthlyIncome', ]\n",
    "\n",
    "# indicators are not touched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling and label encoding is done on data_full. After we will do resampling\n",
    "# In this way coding and scaling cover entire range of values, not only for resampled data\n",
    "\n",
    "# we don't need any scaling (it is ensambles of trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat cols treatment\n",
    "# Code categorical columns (only season, weather, year)\n",
    "\n",
    "# we don't need any pre-processing for cat columns\n",
    "\n",
    "# so for XGBoost afpret Nan treatment no other pre-processing is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estrae X: matrice features ed y, labels\n",
    "y_train_full = data_full[TARGET].values\n",
    "x_train_full = data_full.drop(TARGET, axis = 1).values\n",
    "\n",
    "assert x_train_full.shape[1] == N_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples in full dataset: 150000\n"
     ]
    }
   ],
   "source": [
    "print(f'# of samples in full dataset: {x_train_full.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples in resampled dataset: 60156\n",
      "# of positive samples: 10026\n",
      "# of negative samples: 50130\n"
     ]
    }
   ],
   "source": [
    "# do the undersampling of the negative class, using IMblearn\n",
    "rus = RandomUnderSampler(sampling_strategy=RATIO, random_state=SEED)\n",
    "\n",
    "x_train, y_train = rus.fit_resample(x_train_full, y_train_full)\n",
    "\n",
    "print(f'# of samples in resampled dataset: {x_train.shape[0]}')\n",
    "\n",
    "# check ratio of classes\n",
    "print(f'# of positive samples: {np.sum(y_train)}')\n",
    "print(f'# of negative samples: {x_train.shape[0] - np.sum(y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resampled dataset (x_train, y_train) will be used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the HPO session with Optuna\n",
    "FOLDS = 5\n",
    "SEED = 4321\n",
    "\n",
    "N_TRIALS = 100\n",
    "TIME_BUDGET = 7200\n",
    "STUDY_NAME = \"xgb01\"\n",
    "\n",
    "# ranges\n",
    "LR_LOW = 1e-3\n",
    "LR_HIGH = 1e-2\n",
    "DEPTH_LOW = 3\n",
    "DEPTH_HIGH = 7\n",
    "N_ITER_LIST = [1000, 1100, 1200, 1300, 1400, 1500]\n",
    "GAMMA_LOW = 0.1\n",
    "GAMMA_HIGH = 5\n",
    "SUBSAMPLE_LOW = 0.1\n",
    "SUBSAMPLE_HIGH = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-15 14:26:09,984]\u001b[0m A new study created in RDB with name: xgb01\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here we define the strategy, the space for hyper-parameters we want to explore\n",
    "#\n",
    "params = {\n",
    "    \"n_estimators\": CategoricalDistribution(N_ITER_LIST),\n",
    "    \"learning_rate\": LogUniformDistribution(low=LR_LOW, high=LR_HIGH),\n",
    "    \"max_depth\": IntUniformDistribution(DEPTH_LOW, DEPTH_HIGH),\n",
    "    \"gamma\" : LogUniformDistribution(low=GAMMA_LOW, high=GAMMA_HIGH),\n",
    "    \"subsample\" : UniformDistribution(low=SUBSAMPLE_LOW, high=SUBSAMPLE_HIGH),\n",
    "    \"tree_method\": \"gpu_hist\"\n",
    "}\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "# per lista scorer sorted(sklearn.metrics.SCORERS.keys())\n",
    "tuner = ADSTuner(clf, cv=FOLDS, strategy=params, scoring=\"roc_auc\", study_name=STUDY_NAME, n_jobs=8, random_state=SEED)\n",
    "\n",
    "tuner.tune(x_train, y_train, exit_criterion=[TimeBudget(TIME_BUDGET)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tuner status is: State.COMPLETED\n",
      "Remaining time is: 0 sec.\n"
     ]
    }
   ],
   "source": [
    "# get the status to see if completed\n",
    "print(f\"The tuner status is: {tuner.get_status()}\")\n",
    "\n",
    "print(f\"Remaining time is: {round(tuner.time_remaining, 1)} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_gamma</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>user_attrs_metric</th>\n",
       "      <th>user_attrs_split0_test_score</th>\n",
       "      <th>user_attrs_split1_test_score</th>\n",
       "      <th>user_attrs_split2_test_score</th>\n",
       "      <th>user_attrs_split3_test_score</th>\n",
       "      <th>user_attrs_split4_test_score</th>\n",
       "      <th>user_attrs_std_fit_time</th>\n",
       "      <th>user_attrs_std_score_time</th>\n",
       "      <th>user_attrs_std_test_score</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>632</td>\n",
       "      <td>0.866993</td>\n",
       "      <td>2022-03-15 16:04:10.960568</td>\n",
       "      <td>2022-03-15 16:05:25.068688</td>\n",
       "      <td>0 days 00:01:14.108120</td>\n",
       "      <td>0.700784</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>4</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.117467</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.866174</td>\n",
       "      <td>0.862284</td>\n",
       "      <td>0.866723</td>\n",
       "      <td>0.866212</td>\n",
       "      <td>0.873570</td>\n",
       "      <td>0.070236</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>458</td>\n",
       "      <td>0.866990</td>\n",
       "      <td>2022-03-15 15:37:13.006136</td>\n",
       "      <td>2022-03-15 15:38:29.168274</td>\n",
       "      <td>0 days 00:01:16.162138</td>\n",
       "      <td>0.409126</td>\n",
       "      <td>0.007659</td>\n",
       "      <td>4</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.110838</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.866183</td>\n",
       "      <td>0.862387</td>\n",
       "      <td>0.866566</td>\n",
       "      <td>0.866149</td>\n",
       "      <td>0.873665</td>\n",
       "      <td>0.379592</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>689</td>\n",
       "      <td>0.866976</td>\n",
       "      <td>2022-03-15 16:12:31.022762</td>\n",
       "      <td>2022-03-15 16:13:42.820140</td>\n",
       "      <td>0 days 00:01:11.797378</td>\n",
       "      <td>2.424337</td>\n",
       "      <td>0.008471</td>\n",
       "      <td>4</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.117470</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.866212</td>\n",
       "      <td>0.862263</td>\n",
       "      <td>0.866722</td>\n",
       "      <td>0.866140</td>\n",
       "      <td>0.873546</td>\n",
       "      <td>0.115466</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>454</td>\n",
       "      <td>0.866960</td>\n",
       "      <td>2022-03-15 15:36:44.578812</td>\n",
       "      <td>2022-03-15 15:37:58.977035</td>\n",
       "      <td>0 days 00:01:14.398223</td>\n",
       "      <td>0.411172</td>\n",
       "      <td>0.008502</td>\n",
       "      <td>4</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.112376</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.865887</td>\n",
       "      <td>0.862440</td>\n",
       "      <td>0.866563</td>\n",
       "      <td>0.866322</td>\n",
       "      <td>0.873589</td>\n",
       "      <td>0.106448</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>287</td>\n",
       "      <td>0.866925</td>\n",
       "      <td>2022-03-15 15:11:33.397899</td>\n",
       "      <td>2022-03-15 15:12:40.018780</td>\n",
       "      <td>0 days 00:01:06.620881</td>\n",
       "      <td>0.492040</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>4</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.866046</td>\n",
       "      <td>0.862187</td>\n",
       "      <td>0.866608</td>\n",
       "      <td>0.866027</td>\n",
       "      <td>0.873758</td>\n",
       "      <td>0.113904</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>564</td>\n",
       "      <td>0.866919</td>\n",
       "      <td>2022-03-15 15:51:53.259272</td>\n",
       "      <td>2022-03-15 15:53:03.572120</td>\n",
       "      <td>0 days 00:01:10.312848</td>\n",
       "      <td>0.634974</td>\n",
       "      <td>0.007761</td>\n",
       "      <td>4</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.117599</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.866076</td>\n",
       "      <td>0.862603</td>\n",
       "      <td>0.866481</td>\n",
       "      <td>0.865988</td>\n",
       "      <td>0.873446</td>\n",
       "      <td>0.720901</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>0.866918</td>\n",
       "      <td>2022-03-15 15:28:24.922409</td>\n",
       "      <td>2022-03-15 15:29:39.353112</td>\n",
       "      <td>0 days 00:01:14.430703</td>\n",
       "      <td>0.651275</td>\n",
       "      <td>0.008343</td>\n",
       "      <td>4</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.117284</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.866261</td>\n",
       "      <td>0.862142</td>\n",
       "      <td>0.866572</td>\n",
       "      <td>0.865895</td>\n",
       "      <td>0.873716</td>\n",
       "      <td>0.080520</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>451</td>\n",
       "      <td>0.866914</td>\n",
       "      <td>2022-03-15 15:35:58.992805</td>\n",
       "      <td>2022-03-15 15:37:13.319584</td>\n",
       "      <td>0 days 00:01:14.326779</td>\n",
       "      <td>0.399753</td>\n",
       "      <td>0.008491</td>\n",
       "      <td>4</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.112311</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.865881</td>\n",
       "      <td>0.862446</td>\n",
       "      <td>0.866359</td>\n",
       "      <td>0.866245</td>\n",
       "      <td>0.873637</td>\n",
       "      <td>0.207335</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>562</td>\n",
       "      <td>0.866910</td>\n",
       "      <td>2022-03-15 15:51:45.318048</td>\n",
       "      <td>2022-03-15 15:52:55.563036</td>\n",
       "      <td>0 days 00:01:10.244988</td>\n",
       "      <td>0.925434</td>\n",
       "      <td>0.007035</td>\n",
       "      <td>4</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.117688</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.866013</td>\n",
       "      <td>0.862354</td>\n",
       "      <td>0.866628</td>\n",
       "      <td>0.866057</td>\n",
       "      <td>0.873497</td>\n",
       "      <td>0.569373</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>687</td>\n",
       "      <td>0.866904</td>\n",
       "      <td>2022-03-15 16:12:19.303315</td>\n",
       "      <td>2022-03-15 16:13:31.797073</td>\n",
       "      <td>0 days 00:01:12.493758</td>\n",
       "      <td>2.394430</td>\n",
       "      <td>0.008625</td>\n",
       "      <td>4</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.117505</td>\n",
       "      <td>...</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.866063</td>\n",
       "      <td>0.862194</td>\n",
       "      <td>0.866685</td>\n",
       "      <td>0.866116</td>\n",
       "      <td>0.873462</td>\n",
       "      <td>0.155981</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number     value             datetime_start          datetime_complete  \\\n",
       "632     632  0.866993 2022-03-15 16:04:10.960568 2022-03-15 16:05:25.068688   \n",
       "458     458  0.866990 2022-03-15 15:37:13.006136 2022-03-15 15:38:29.168274   \n",
       "689     689  0.866976 2022-03-15 16:12:31.022762 2022-03-15 16:13:42.820140   \n",
       "454     454  0.866960 2022-03-15 15:36:44.578812 2022-03-15 15:37:58.977035   \n",
       "287     287  0.866925 2022-03-15 15:11:33.397899 2022-03-15 15:12:40.018780   \n",
       "564     564  0.866919 2022-03-15 15:51:53.259272 2022-03-15 15:53:03.572120   \n",
       "400     400  0.866918 2022-03-15 15:28:24.922409 2022-03-15 15:29:39.353112   \n",
       "451     451  0.866914 2022-03-15 15:35:58.992805 2022-03-15 15:37:13.319584   \n",
       "562     562  0.866910 2022-03-15 15:51:45.318048 2022-03-15 15:52:55.563036   \n",
       "687     687  0.866904 2022-03-15 16:12:19.303315 2022-03-15 16:13:31.797073   \n",
       "\n",
       "                  duration  params_gamma  params_learning_rate  \\\n",
       "632 0 days 00:01:14.108120      0.700784              0.008390   \n",
       "458 0 days 00:01:16.162138      0.409126              0.007659   \n",
       "689 0 days 00:01:11.797378      2.424337              0.008471   \n",
       "454 0 days 00:01:14.398223      0.411172              0.008502   \n",
       "287 0 days 00:01:06.620881      0.492040              0.008455   \n",
       "564 0 days 00:01:10.312848      0.634974              0.007761   \n",
       "400 0 days 00:01:14.430703      0.651275              0.008343   \n",
       "451 0 days 00:01:14.326779      0.399753              0.008491   \n",
       "562 0 days 00:01:10.244988      0.925434              0.007035   \n",
       "687 0 days 00:01:12.493758      2.394430              0.008625   \n",
       "\n",
       "     params_max_depth  params_n_estimators  params_subsample  ...  \\\n",
       "632                 4                 1500          0.117467  ...   \n",
       "458                 4                 1500          0.110838  ...   \n",
       "689                 4                 1500          0.117470  ...   \n",
       "454                 4                 1500          0.112376  ...   \n",
       "287                 4                 1400          0.117600  ...   \n",
       "564                 4                 1500          0.117599  ...   \n",
       "400                 4                 1500          0.117284  ...   \n",
       "451                 4                 1500          0.112311  ...   \n",
       "562                 4                 1500          0.117688  ...   \n",
       "687                 4                 1500          0.117505  ...   \n",
       "\n",
       "    user_attrs_metric  user_attrs_split0_test_score  \\\n",
       "632           roc_auc                      0.866174   \n",
       "458           roc_auc                      0.866183   \n",
       "689           roc_auc                      0.866212   \n",
       "454           roc_auc                      0.865887   \n",
       "287           roc_auc                      0.866046   \n",
       "564           roc_auc                      0.866076   \n",
       "400           roc_auc                      0.866261   \n",
       "451           roc_auc                      0.865881   \n",
       "562           roc_auc                      0.866013   \n",
       "687           roc_auc                      0.866063   \n",
       "\n",
       "     user_attrs_split1_test_score  user_attrs_split2_test_score  \\\n",
       "632                      0.862284                      0.866723   \n",
       "458                      0.862387                      0.866566   \n",
       "689                      0.862263                      0.866722   \n",
       "454                      0.862440                      0.866563   \n",
       "287                      0.862187                      0.866608   \n",
       "564                      0.862603                      0.866481   \n",
       "400                      0.862142                      0.866572   \n",
       "451                      0.862446                      0.866359   \n",
       "562                      0.862354                      0.866628   \n",
       "687                      0.862194                      0.866685   \n",
       "\n",
       "    user_attrs_split3_test_score  user_attrs_split4_test_score  \\\n",
       "632                     0.866212                      0.873570   \n",
       "458                     0.866149                      0.873665   \n",
       "689                     0.866140                      0.873546   \n",
       "454                     0.866322                      0.873589   \n",
       "287                     0.866027                      0.873758   \n",
       "564                     0.865988                      0.873446   \n",
       "400                     0.865895                      0.873716   \n",
       "451                     0.866245                      0.873637   \n",
       "562                     0.866057                      0.873497   \n",
       "687                     0.866116                      0.873462   \n",
       "\n",
       "     user_attrs_std_fit_time  user_attrs_std_score_time  \\\n",
       "632                 0.070236                   0.003321   \n",
       "458                 0.379592                   0.008393   \n",
       "689                 0.115466                   0.001781   \n",
       "454                 0.106448                   0.001292   \n",
       "287                 0.113904                   0.002878   \n",
       "564                 0.720901                   0.001339   \n",
       "400                 0.080520                   0.002193   \n",
       "451                 0.207335                   0.002506   \n",
       "562                 0.569373                   0.002501   \n",
       "687                 0.155981                   0.006770   \n",
       "\n",
       "     user_attrs_std_test_score     state  \n",
       "632                   0.003655  COMPLETE  \n",
       "458                   0.003668  COMPLETE  \n",
       "689                   0.003653  COMPLETE  \n",
       "454                   0.003636  COMPLETE  \n",
       "287                   0.003763  COMPLETE  \n",
       "564                   0.003549  COMPLETE  \n",
       "400                   0.003758  COMPLETE  \n",
       "451                   0.003660  COMPLETE  \n",
       "562                   0.003626  COMPLETE  \n",
       "687                   0.003649  COMPLETE  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look only at completed trials, sorted with best on top. Metric chosen is in the value col.\n",
    "result_df = tuner.trials[tuner.trials[\"state\"] == \"COMPLETE\"].sort_values(\n",
    "    by=[\"value\"], ascending=False\n",
    ")\n",
    "\n",
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADSTuner session results:\n",
      "ADSTuner has launched 779 trials\n",
      "ADSTuner has completed 779 trials\n",
      "\n",
      "The best trial is the #: 632\n",
      "Parameters for the best trial are: {'gamma': 0.7007836747317996, 'learning_rate': 0.008389825517656139, 'max_depth': 4, 'n_estimators': 1500, 'subsample': 0.11746700590625371, 'tree_method': 'gpu_hist'}\n",
      "The metric used to optimize is: roc_auc\n",
      "The best score is: 0.867\n"
     ]
    }
   ],
   "source": [
    "def show_tuner_results(tuner):\n",
    "\n",
    "    # to count completed\n",
    "    result_df = tuner.trials[tuner.trials[\"state\"] == \"COMPLETE\"].sort_values(\n",
    "        by=[\"value\"], ascending=False\n",
    "    )\n",
    "\n",
    "    print(\"ADSTuner session results:\")\n",
    "    print(f\"ADSTuner has launched {tuner.trials.shape[0]} trials\")\n",
    "    print(f\"ADSTuner has completed {result_df.shape[0]} trials\")\n",
    "    print()\n",
    "    print(f\"The best trial is the #: {tuner.best_index}\")\n",
    "    print(f\"Parameters for the best trial are: {tuner.best_params}\")\n",
    "    print(f\"The metric used to optimize is: {tuner.scoring_name}\")\n",
    "    print(f\"The best score is: {round(tuner.best_score, 4)}\")\n",
    "    \n",
    "show_tuner_results(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.82164\n",
      "[100]\tvalidation_0-auc:0.85831\n",
      "[200]\tvalidation_0-auc:0.86125\n",
      "[300]\tvalidation_0-auc:0.86423\n",
      "[400]\tvalidation_0-auc:0.86645\n",
      "[500]\tvalidation_0-auc:0.86841\n",
      "[600]\tvalidation_0-auc:0.86985\n",
      "[700]\tvalidation_0-auc:0.87096\n",
      "[800]\tvalidation_0-auc:0.87184\n",
      "[900]\tvalidation_0-auc:0.87264\n",
      "[1000]\tvalidation_0-auc:0.87343\n",
      "[1100]\tvalidation_0-auc:0.87408\n",
      "[1200]\tvalidation_0-auc:0.87467\n",
      "[1300]\tvalidation_0-auc:0.87522\n",
      "[1400]\tvalidation_0-auc:0.87574\n",
      "[1499]\tvalidation_0-auc:0.87637\n",
      "\n",
      "CPU times: user 2.9 s, sys: 704 ms, total: 3.6 s\n",
      "Wall time: 3.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = xgb.XGBClassifier(**tuner.best_params)\n",
    "\n",
    "# addestro e valuto su train e su validation set\n",
    "clf.fit(x_train, y_train,\n",
    "        eval_set=[(x_train, y_train)],\n",
    "        eval_metric='auc', verbose=100)\n",
    "\n",
    "print()\n",
    "\n",
    "evals_result = clf.evals_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OK, consider that the slightly higher AUC is due to the fact here we're evaluating also on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc(train_hist):\n",
    "    plt.figure(figsize=(9,6))\n",
    "    \n",
    "    plt.plot(train_hist, label='Training AUC')\n",
    "    plt.title('AUC')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('auc')\n",
    "    plt.xlabel('n_estimator')\n",
    "    plt.grid(True)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = evals_result['validation_0']['auc']\n",
    "\n",
    "plot_auc(train_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 92.68%\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy on full dataset\n",
    "y_pred = clf.predict(x_train_full)\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_train_full, predictions)\n",
    "\n",
    "print(\"Accuracy on train set: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute confusion matrix on full dataset\n",
    "cm = confusion_matrix(y_train_full, predictions)\n",
    "\n",
    "# plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of FN is rather high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the TEST set (for submission to Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on test set\n",
    "orig_test = pd.read_csv('cs-test.csv')\n",
    "\n",
    "# inpute missing values, add the two indicator columns\n",
    "orig_test['isna_mi'] = 0\n",
    "orig_test.loc[orig_test[COL1_MISSING].isna(), 'isna_mi'] = 1\n",
    "orig_test.loc[orig_test[COL1_MISSING].isna(), COL1_MISSING] = MONTHLY_INC_MEDIAN\n",
    "\n",
    "orig_test['isna_nod'] = 0\n",
    "orig_test.loc[orig_test[COL2_MISSING].isna(), 'isna_nod'] = 1\n",
    "orig_test.loc[orig_test[COL2_MISSING].isna(), COL2_MISSING] = N_OF_DEP_MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test = orig_test[ind_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test = orig_test.drop(ind_col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COL_NAME = 'Unnamed: 0'\n",
    "xorig_test = orig_test.drop(ID_COL_NAME, axis = 1)\n",
    "xorig_test = xorig_test.drop(TARGET, axis = 1)\n",
    "\n",
    "x_test = xorig_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggiungi qui lo scaling !!!\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "# riaggiunge le colonne indicatore\n",
    "x_test_scaled = np.c_[x_test_scaled, ind_test]\n",
    "\n",
    "assert x_test_scaled.shape[1] == N_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do predictions on test set (no shuffle !)\n",
    "y_pred = clf.predict_proba(x_test_scaled)\n",
    "\n",
    "# y_pred contiene le probabilità\n",
    "y_pred = y_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepara il csv per la submission\n",
    "result_dict = {\"Id\": orig_test[ID_COL_NAME].values,\n",
    "              'Probability': y_pred}\n",
    "\n",
    "FILE_SUB = 'submission25.csv'\n",
    "\n",
    "# build a dataframe and save to csv\n",
    "result_df = pd.DataFrame(result_dict)\n",
    "\n",
    "result_df.to_csv(FILE_SUB, index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Modela and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model: uso un formato semplice: pkl\n",
    "pickle.dump(clf, open(\"credit-scoring.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvo anche lo scaler\n",
    "pickle.dump(scaler, open(\"scaler.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the model\n",
    "loaded_model = pickle.load(open(\"credit-scoring.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the scaler\n",
    "loaded_scaler = pickle.load(open(\"scaler.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for online predictions\n",
    "# input are given as a numpy array, with no missing fields, but we need to add the two indicator columns\n",
    "x_input = np.array([[1,2,3,4,5,6,7,8,9,10],\n",
    "                   [1,2,3,4,5,6,7,8,9,10],\n",
    "                   [1,2,3,4,5,6,7,8,9,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlli\n",
    "assert x_input.shape[1] == 10\n",
    "# check there are no null\n",
    "assert np.sum(np.isnan(x_input)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "x_input_scaled = loaded_scaler.transform(x_input)\n",
    "\n",
    "# add two columns with 0\n",
    "x_add = np.zeros((x_input.shape[0], 2))\n",
    "x_input_scaled = np.c_[x_input_scaled, x_add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(x_input_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[TARGET].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
